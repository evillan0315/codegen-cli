{
  "timestamp": "2025-08-13T02:17:29.433Z",
  "prompt": "\n# AI Code Generation Request\n\n## User Request\n```text\nUpdate src/llm/llmOrchestrator to use the NestJS api for generate content in /media/eddie/Data/projects/nestJS/nest-modules/full-stack/src/google/google-gemini/google-gemini-file\n```\n\n## Project Context\n  - ../\n    - ../../\n      - ../../full-stack/\n        - ../../full-stack/src/\n          - ../../full-stack/src/google/\n            - ../../full-stack/src/google/google-gemini/\n              - ../../full-stack/src/google/google-gemini/google-gemini-file/\n                - ../../full-stack/src/google/google-gemini/google-gemini-file/dto/\n                  - ../../full-stack/src/google/google-gemini/google-gemini-file/dto/enhance-resume.dto.ts\n                  - ../../full-stack/src/google/google-gemini/google-gemini-file/dto/generate-file.dto.ts\n                  - ../../full-stack/src/google/google-gemini/google-gemini-file/dto/generate-image-base64.dto.ts\n                  - ../../full-stack/src/google/google-gemini/google-gemini-file/dto/generate-resume.dto.ts\n                  - ../../full-stack/src/google/google-gemini/google-gemini-file/dto/generate-text.dto.ts\n                  - ../../full-stack/src/google/google-gemini/google-gemini-file/dto/index.ts\n                  - ../../full-stack/src/google/google-gemini/google-gemini-file/dto/optimization-result.dto.ts\n                  - ../../full-stack/src/google/google-gemini/google-gemini-file/dto/optimize-resume.dto.ts\n                - ../../full-stack/src/google/google-gemini/google-gemini-file/enum/\n                  - ../../full-stack/src/google/google-gemini/google-gemini-file/enum/google-gemini-file.enum.ts\n                - ../../full-stack/src/google/google-gemini/google-gemini-file/google-gemini-audio.service.ts\n                - ../../full-stack/src/google/google-gemini/google-gemini-file/google-gemini-file.controller.ts\n                - ../../full-stack/src/google/google-gemini/google-gemini-file/google-gemini-file.decorator.ts\n                - ../../full-stack/src/google/google-gemini/google-gemini-file/google-gemini-file.service.ts\n                - ../../full-stack/src/google/google-gemini/google-gemini-file/interfaces/\n                  - ../../full-stack/src/google/google-gemini/google-gemini-file/interfaces/generate-file.interface.ts\n                  - ../../full-stack/src/google/google-gemini/google-gemini-file/interfaces/generate-image-base64.interface.ts\n                  - ../../full-stack/src/google/google-gemini/google-gemini-file/interfaces/generate-text.interface.ts\n  - src/\n    - src/llm/\n      - src/llm/contextPreparer.ts\n      - src/llm/jsonRepair.ts\n      - src/llm/llmOrchestrator.ts\n\n### Relevant Files (for analysis)\n```files\n// File: ../../full-stack/src/google/google-gemini/google-gemini-file/google-gemini-audio.service.ts\nimport {\n  Injectable,\n  InternalServerErrorException,\n  Logger,\n} from '@nestjs/common';\nimport { ConfigService } from '@nestjs/config';\nimport { GoogleGenerativeAI, Part } from '@google/generative-ai';\n\n@Injectable()\nexport class GeminiService {\n  private readonly genAI: GoogleGenerativeAI;\n  private readonly logger = new Logger(GeminiService.name);\n\n  constructor(private configService: ConfigService) {\n    const apiKey = this.configService.get<string>('geminiApiKey');\n    if (!apiKey) {\n      this.logger.error('GEMINI_API_KEY is not set in environment variables.');\n      throw new InternalServerErrorException('Gemini API key is missing.');\n    }\n    this.genAI = new GoogleGenerativeAI(apiKey);\n  }\n\n  /**\n   * Converts a Buffer to a Generative Part for inline data.\n   * @param data The audio file buffer.\n   * @param mimeType The MIME type of the audio (e.g., 'audio/wav', 'audio/mpeg').\n   * @returns A Part object suitable for the Gemini API.\n   */\n  private bufferToGenerativePart(data: Buffer, mimeType: string): Part {\n    return {\n      inlineData: {\n        data: data.toString('base64'),\n        mimeType,\n      },\n    };\n  }\n\n  /**\n   * Transcribes audio using the Google Gemini API.\n   * @param audioBuffer The audio file as a Buffer.\n   * @param mimeType The MIME type of the audio (e.g., 'audio/wav', 'audio/mpeg').\n   * @returns The transcribed text.\n   */\n  async transcribeAudio(\n    audioBuffer: Buffer,\n    mimeType: string,\n  ): Promise<string> {\n    try {\n      // Use a model that supports multimodal input (like gemini-1.5-flash or gemini-1.5-pro)\n      const model = this.genAI.getGenerativeModel({\n        model: 'gemini-1.5-flash',\n      }); // [1]\n\n      const audioPart = this.bufferToGenerativePart(audioBuffer, mimeType);\n\n      // Send the audio part with a prompt to transcribe it.\n      const result = await model.generateContent([\n        audioPart,\n        { text: 'Transcribe this audio.' }, // Specific prompt to get the transcription. [7]\n      ]);\n\n      const response = await result.response;\n      const transcription = response.text();\n\n      this.logger.log('Audio successfully transcribed by Gemini.');\n      return transcription;\n    } catch (error) {\n      this.logger.error(\n        `Error transcribing audio with Gemini: ${error.message}`,\n      );\n      throw new InternalServerErrorException(\n        'Failed to transcribe audio with Gemini.',\n      );\n    }\n  }\n}\n\n\n// File: ../../full-stack/src/google/google-gemini/google-gemini-file/google-gemini-file.controller.ts\n// src/google/google-gemini/google-gemini-file/google-gemini-file.controller.ts\nimport {\n  Controller,\n  Post,\n  Body,\n  UseInterceptors,\n  UploadedFile,\n  HttpCode,\n  HttpStatus,\n  BadRequestException,\n  UseGuards,\n} from '@nestjs/common';\nimport { FileInterceptor } from '@nestjs/platform-express';\n\nimport { GoogleGeminiFileService } from './google-gemini-file.service';\nimport {\n  GenerateTextDto,\n  GenerateImageBase64Dto,\n  GenerateFileDto,\n} from './dto';\n\nimport {\n  ApiTags,\n  ApiOperation,\n  ApiResponse,\n  ApiConsumes,\n  ApiBody,\n  ApiCreatedResponse,\n  ApiBearerAuth,\n} from '@nestjs/swagger';\n\nimport { JwtAuthGuard } from '../../../auth/auth.guard';\nimport { RolesGuard } from '../../../auth/guards/roles.guard';\nimport { Roles } from '../../../auth/decorators/roles.decorator';\nimport { UserRole } from '../../../auth/enums/user-role.enum';\n\n@ApiBearerAuth()\n@UseGuards(JwtAuthGuard, RolesGuard)\n@ApiTags('Gemini AI')\n@Controller('api/gemini/file')\nexport class GoogleGeminiFileController {\n  constructor(\n    private readonly googleGeminiFileService: GoogleGeminiFileService,\n  ) {}\n\n  @Post('generate-text')\n  @Roles(UserRole.USER, UserRole.ADMIN, UserRole.MANAGER)\n  @HttpCode(HttpStatus.OK)\n  @ApiOperation({ summary: 'Generate text from a simple text prompt.' })\n  @ApiResponse({\n    status: 200,\n    description: 'Generated text content.',\n    type: String,\n    example: 'Once upon a time...',\n  })\n  @ApiResponse({ status: 500, description: 'Internal Server Error' })\n  async generateText(\n    @Body() generateTextDto: GenerateTextDto,\n  ): Promise<string> {\n    console.log(generateTextDto, 'generateTextDto');\n    return this.googleGeminiFileService.generateText(generateTextDto);\n  }\n\n  @Post('generate-image-base64')\n  @Roles(UserRole.USER, UserRole.ADMIN, UserRole.MANAGER)\n  @HttpCode(HttpStatus.OK)\n  @ApiOperation({\n    summary: 'Generate text from a prompt with an embedded Base64 image.',\n  })\n  @ApiCreatedResponse({\n    description: 'Generated text content based on the image and text prompt.',\n    type: String,\n    example:\n      'The image shows a sunny landscape with green hills and a clear blue sky.',\n  })\n  @ApiResponse({ status: 500, description: 'Internal Server Error' })\n  async generateTextWithBase64Image(\n    @Body() generateImageBase64Dto: GenerateImageBase64Dto,\n  ): Promise<string> {\n    return this.googleGeminiFileService.generateTextWithBase64Image(\n      generateImageBase64Dto,\n    );\n  }\n\n  @Post('generate-file')\n  @Roles(UserRole.USER, UserRole.ADMIN, UserRole.MANAGER)\n  @HttpCode(HttpStatus.OK)\n  @ApiOperation({\n    summary:\n      'Generate text from a prompt with an uploaded file (e.g., .sql, .txt).',\n  })\n  @ApiConsumes('multipart/form-data')\n  @ApiBody({\n    description:\n      'Prompt text and the file to be analyzed, with optional system instruction and conversation ID.',\n    schema: {\n      type: 'object',\n      properties: {\n        prompt: {\n          type: 'string',\n          description: 'The text prompt for Gemini.',\n          example: 'Analyze this SQL schema and suggest improvements.',\n        },\n        systemInstruction: {\n          type: 'string',\n          description: 'Optional system instruction for the model.',\n          example: 'Act as a code reviewer.',\n        }, // Removed required: false (it's implicit)\n        conversationId: {\n          type: 'string',\n          format: 'uuid',\n          description: 'Optional ID of an ongoing conversation.',\n          example: 'a1b2c3d4-e5f6-7890-1234-567890abcdef',\n        }, // Removed required: false\n        file: {\n          type: 'string',\n          format: 'binary',\n          description: 'The file to attach (e.g., .sql, .txt, .csv).',\n        },\n      },\n      // Explicitly list required fields at the schema level\n      required: ['prompt', 'file'],\n    },\n  })\n  @ApiCreatedResponse({\n    description: 'Generated text content based on the file and text prompt.',\n    type: String,\n    example:\n      'The SQL schema defines tables for users, orders, and products. Consider adding indexes for faster lookups.',\n  })\n  @ApiResponse({ status: 500, description: 'Internal Server Error' })\n  @UseInterceptors(FileInterceptor('file'))\n  async generateTextWithFile(\n    @UploadedFile() file: Express.Multer.File, // Move required parameter first\n    @Body('prompt') prompt: string,\n    @Body('systemInstruction') systemInstruction?: string,\n    @Body('conversationId') conversationId?: string,\n  ): Promise<string> {\n    if (!file) {\n      throw new BadRequestException('No file provided for analysis.');\n    }\n    if (!prompt) {\n      throw new BadRequestException('Prompt is required.');\n    }\n    return this.googleGeminiFileService.generateTextWithFile(\n      prompt,\n      file,\n      systemInstruction,\n      conversationId,\n    );\n  }\n}\n\n\n// File: ../../full-stack/src/google/google-gemini/google-gemini-file/google-gemini-file.decorator.ts\nimport { SetMetadata } from '@nestjs/common';\n\nexport const GoogleGeminiFile = (...args: string[]) =>\n  SetMetadata('google-gemini-file', args);\n\n\n// File: ../../full-stack/src/google/google-gemini/google-gemini-file/google-gemini-file.service.ts\n// full-stack/src/google/google-gemini/google-gemini-file/google-gemini-file.service.ts\nimport {\n  Injectable,\n  Logger,\n  InternalServerErrorException,\n  Inject,\n  Scope,\n  BadRequestException,\n} from '@nestjs/common';\nimport {\n  GenerateTextDto,\n  GenerateImageBase64Dto,\n  GenerateResumeDto,\n  OptimizeResumeDto,\n  EnhanceResumeDto,\n  OptimizationResultDto,\n} from './dto'; // Ensure these DTOs are correctly imported\n\n// DTO for file upload, not necessarily tied to Multer directly in the service's API\nexport interface GenerateFileInternalDto {\n  prompt: string;\n  systemInstruction?: string;\n  conversationId?: string;\n  base64Data: string;\n  mimeType: string;\n}\n\nimport { ModuleControlService } from '../../../module-control/module-control.service';\nimport { PrismaService } from '../../../prisma/prisma.service';\nimport { ConversationService } from '../../../conversation/conversation.service';\n// import { HighlightCodeService } from '../../../utils/highlight.service'; // Removed, as it's not used\nimport { RequestType, Prisma } from '@prisma/client'; // Assuming RequestType is extended\nimport { REQUEST } from '@nestjs/core';\nimport { Request } from 'express';\nimport { CreateJwtUserDto } from '../../../auth/dto/auth.dto';\nimport { v4 as uuidv4 } from 'uuid';\nimport { EventEmitter2 } from '@nestjs/event-emitter';\nimport { lookup as mimeLookup } from 'mime-types';\nimport { ConversationHistoryItemDto } from '../../../conversation/dto/conversation-history-item.dto';\nimport { PaginationDto } from '../../../common/dto/pagination.dto';\nimport { PaginatedResponseDto } from '../../../common/dto/paginated-response.dto';\n//import { RequestType } from './enum/google-gemini-file.enum';\n// Extend RequestType enum (if not already done in Prisma schema or a separate file)\n// This is for demonstration; adapt based on your actual enum definition.\n// For Prisma, you might update your schema.prisma file and then run `npx prisma generate`\n// For a local enum, define it like so:\n/*\nexport enum RequestType {\n  TEXT_ONLY = 'TEXT_ONLY',\n  TEXT_WITH_IMAGE = 'TEXT_WITH_IMAGE',\n  TEXT_WITH_FILE = 'TEXT_WITH_FILE',\n  RESUME_GENERATION = 'RESUME_GENERATION',\n  RESUME_OPTIMIZATION = 'RESUME_OPTIMIZATION',\n  RESUME_ENHANCEMENT = 'RESUME_ENHANCEMENT',\n}\n*/\n\n@Injectable({ scope: Scope.REQUEST })\nexport class GoogleGeminiFileService {\n  private readonly logger = new Logger(GoogleGeminiFileService.name);\n  // Consider using NestJS ConfigModule for managing environment variables\n  // https://docs.nestjs.com/techniques/configuration\n  private readonly GEMINI_API_KEY = process.env.GOOGLE_GEMINI_API_KEY;\n  private readonly GOOGLE_GEMINI_MODEL = process.env.GOOGLE_GEMINI_MODEL;\n  private readonly GEMINI_API_URL =\n    'https://generativelanguage.googleapis.com/v1beta/models';\n\n  constructor(\n    private readonly moduleControlService: ModuleControlService,\n    private readonly prisma: PrismaService,\n    @Inject(REQUEST)\n    private readonly request: Request & { user?: CreateJwtUserDto },\n    // private readonly highlightCodeService: HighlightCodeService, // Removed as it's not used\n    private readonly eventEmitter: EventEmitter2,\n    private readonly conversationService: ConversationService,\n  ) {\n    if (!this.moduleControlService.isModuleEnabled('GoogleModule')) {\n      this.logger.warn(\n        'Gemini module is disabled according to ModuleControlService. API calls will be blocked.',\n      );\n    }\n    if (!this.GEMINI_API_KEY || !this.GOOGLE_GEMINI_MODEL) {\n      this.logger.error(\n        'Missing GOOGLE_GEMINI_API_KEY or GOOGLE_GEMINI_MODEL environment variables. Gemini functionality will be impaired.',\n      );\n    }\n  }\n\n  private get userId(): string {\n    if (!this.request.user || !this.request.user.id) {\n      throw new InternalServerErrorException(\n        'User ID not found in request context. Authentication might be missing or misconfigured.',\n      );\n    }\n    return this.request.user.id;\n  }\n\n  /**\n   * Fetches conversation history for a given conversation ID.\n   * @param conversationId The ID of the conversation.\n   * @param paginationDto Pagination details (page, limit).\n   * @returns Paginated conversation history.\n   */\n  private async getConversationHistory(\n    conversationId: string,\n    paginationDto: PaginationDto = { page: 1, limit: 20 },\n  ): Promise<PaginatedResponseDto<ConversationHistoryItemDto>> {\n    return this.conversationService.getConversationHistory(\n      conversationId,\n      paginationDto,\n    );\n  }\n\n  /**\n   * Makes a call to the Google Gemini API.\n   * Handles module control check, history de-duplication, and error logging.\n   * @param modelName The Gemini model to use.\n   * @param payload The request payload for the Gemini API.\n   * @param conversationHistory Optional array of previous conversation turns.\n   * @returns The raw response from the Gemini API.\n   */\n  private async callGeminiApi(\n    modelName: string,\n    payload: any,\n    conversationHistory?: ConversationHistoryItemDto[],\n  ): Promise<any> {\n    if (!this.moduleControlService.isModuleEnabled('GoogleModule')) {\n      this.logger.warn(\n        'Gemini API calls are disabled by ModuleControlService. Aborting API call.',\n      );\n      throw new InternalServerErrorException(\n        'Gemini API functionality is currently disabled.',\n      );\n    }\n\n    if (!this.GEMINI_API_KEY || !this.GOOGLE_GEMINI_MODEL) {\n      throw new InternalServerErrorException(\n        'Gemini API key or model name is not configured.',\n      );\n    }\n\n    try {\n      this.logger.debug(`Calling Gemini API for model: ${modelName}`);\n\n      const apiUrl = `${this.GEMINI_API_URL}/${modelName}:generateContent?key=${this.GEMINI_API_KEY}`;\n\n      // Prepend unique history to the current contents\n      if (conversationHistory && conversationHistory.length > 0) {\n        // Create a unique set of history items, excluding `createdAt` for comparison\n        const seen = new Set<string>();\n        const uniqueHistory: Omit<ConversationHistoryItemDto, 'createdAt'>[] = [];\n\n        for (const item of conversationHistory) {\n          // Use a consistent stringification for comparison.\n          // Note: If `parts` can have varying key orders for objects, this needs a deeper sort/stringify.\n          const key = JSON.stringify({ role: item.role, parts: item.parts });\n          if (!seen.has(key)) {\n            seen.add(key);\n            const { createdAt, ...rest } = item; // Exclude createdAt for Gemini API payload\n            uniqueHistory.push(rest);\n          }\n        }\n        payload.contents = [...uniqueHistory, ...payload.contents];\n      }\n\n      this.logger.debug(`Gemini API URL: ${apiUrl}`);\n      // this.logger.debug(`Gemini API Payload: ${JSON.stringify(payload, null, 2)}`); // Be cautious with logging full payloads in production\n\n      const response = await fetch(apiUrl, {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify(payload),\n      });\n\n      if (!response.ok) {\n        const errorData = await response.json();\n        this.logger.error(\n          `Gemini API error (${response.status}): ${JSON.stringify(errorData)}`,\n          errorData,\n        );\n        throw new InternalServerErrorException(\n          `Gemini API error: ${errorData.error?.message || 'Unknown API error'}`,\n        );\n      }\n\n      const result = await response.json();\n\n      if (result.candidates?.[0]?.content?.parts?.length > 0) {\n        return result;\n      } else {\n        this.logger.warn(\n          'Gemini API response structure unexpected or content missing. Raw response:',\n          result,\n        );\n        throw new InternalServerErrorException(\n          'No content found in Gemini API response.',\n        );\n      }\n    } catch (error) {\n      if (error instanceof InternalServerErrorException) throw error;\n      this.logger.error(\n        `Failed to connect to Gemini API: ${error.message}`,\n        error.stack,\n      );\n      throw new InternalServerErrorException(\n        `Failed to connect to Gemini API: ${error.message}`,\n      );\n    }\n  }\n\n  /**\n   * Helper to store Gemini API request and response in the database.\n   * @returns The generated text from Gemini.\n   */\n  private async saveGeminiInteraction(\n    currentUserId: string,\n    prompt: string,\n    modelName: string,\n    requestType: RequestType,\n    geminiApiResult: any,\n    conversationId?: string,\n    systemInstruction?: string,\n    imageData?: string,\n    fileMimeType?: string,\n    fileData?: string,\n  ): Promise<string> {\n    const generatedText = geminiApiResult.candidates[0].content.parts[0].text;\n    const geminiRequest = await this.prisma.geminiRequest.create({\n      data: {\n        userId: currentUserId,\n        conversationId: conversationId,\n        prompt: prompt,\n        systemInstruction: systemInstruction,\n        modelUsed: modelName,\n        requestType: requestType,\n        imageData: imageData,\n        fileMimeType: fileMimeType,\n        fileData: fileData,\n      },\n    });\n\n    await this.prisma.geminiResponse.create({\n      data: {\n        requestId: geminiRequest.id,\n        responseText: generatedText,\n        finishReason: geminiApiResult.candidates[0].finishReason || null,\n        safetyRatings: geminiApiResult.candidates[0].safetyRatings\n          ? JSON.stringify(geminiApiResult.candidates[0].safetyRatings)\n          : Prisma.JsonNull,\n        tokenCount: geminiApiResult.usageMetadata?.totalTokenCount || null,\n      },\n    });\n\n    this.eventEmitter.emit('gemini.new_data', {\n      requestId: geminiRequest.id,\n      conversationId: geminiRequest.conversationId,\n      prompt: geminiRequest.prompt,\n      systemInstruction: geminiRequest.systemInstruction,\n      modelUsed: geminiRequest.modelUsed,\n      responseText: generatedText,\n      createdAt: new Date(),\n    });\n\n    return generatedText;\n  }\n\n  /**\n   * Generic helper to handle common Gemini API call logic for various requests.\n   * @param options.dto The DTO containing prompt, systemInstruction, conversationId.\n   * @param options.requestType The type of request (e.g., TEXT_ONLY, TEXT_WITH_IMAGE).\n   * @param options.getContents A function that returns the specific `contents` array for the Gemini payload.\n   * @param options.saveOptions Additional options for saving the interaction (image data, file data, mime type).\n   * @param options.defaultSystemInstruction A default system instruction if none provided in DTO.\n   * @param options.parseResult A function to parse the Gemini response if it's not just plain text.\n   * @returns The result of the Gemini operation, potentially parsed.\n   */\n  private async _performGeminiOperation<T extends { prompt: string; systemInstruction?: string; conversationId?: string }>(\n    options: {\n      dto: T;\n      requestType: RequestType;\n      getContents: (dto: T) => { role: string; parts: any[] }[];\n      saveOptions?: {\n        imageData?: string;\n        fileMimeType?: string;\n        fileData?: string;\n      };\n      defaultSystemInstruction?: string;\n      parseResult?: (generatedText: string) => any; // Generic parser for complex results\n    },\n  ): Promise<string | OptimizationResultDto> {\n    const { dto, requestType, getContents, saveOptions, defaultSystemInstruction, parseResult } = options;\n    const { prompt, systemInstruction, conversationId } = dto;\n    const currentUserId = this.userId;\n    const modelName = this.GOOGLE_GEMINI_MODEL || 'gemini-2.0-flash';\n\n    let effectiveConversationId = conversationId;\n    if (!effectiveConversationId) {\n      effectiveConversationId = uuidv4();\n    }\n\n    let conversationHistory: ConversationHistoryItemDto[] | undefined;\n    if (conversationId) { // Only attempt to fetch history if a conversationId was provided initially\n      const paginatedResult = await this.getConversationHistory(conversationId);\n      conversationHistory = paginatedResult.data;\n      if (!conversationHistory || conversationHistory.length === 0) {\n        this.logger.debug(\n          `No history found for conversation ID: ${effectiveConversationId}. Starting fresh.`,\n        );\n      }\n    }\n\n    const effectiveSystemInstruction = systemInstruction || defaultSystemInstruction;\n\n    const payload: {\n      contents: { role: string; parts: any[] }[];\n      systemInstruction?: { parts: { text: string }[] };\n    } = {\n      contents: getContents(dto),\n    };\n\n    if (effectiveSystemInstruction) {\n      payload.systemInstruction = {\n        parts: [{ text: effectiveSystemInstruction }],\n      };\n    }\n\n    try {\n      const geminiApiResult = await this.callGeminiApi(\n        modelName,\n        payload,\n        conversationHistory,\n      );\n\n      const generatedText = geminiApiResult.candidates[0].content.parts[0].text;\n\n      // Save the interaction BEFORE parsing the result (original text is saved)\n      await this.saveGeminiInteraction(\n        currentUserId,\n        prompt,\n        modelName,\n        requestType,\n        geminiApiResult,\n        effectiveConversationId,\n        effectiveSystemInstruction,\n        saveOptions?.imageData,\n        saveOptions?.fileMimeType,\n        saveOptions?.fileData,\n      );\n\n      // Parse the result if a parser function is provided\n      if (parseResult) {\n        return parseResult(generatedText);\n      }\n\n      return generatedText;\n    } catch (error) {\n      this.logger.error(\n        `Error in Gemini operation [${requestType}] or saving response: ${error.message}`,\n        error.stack,\n      );\n      throw error;\n    }\n  }\n\n  async generateText(generateTextDto: GenerateTextDto): Promise<string> {\n    return this._performGeminiOperation({\n      dto: generateTextDto,\n      requestType: RequestType.TEXT_ONLY,\n      getContents: (dto) => [{ role: 'user', parts: [{ text: dto.prompt }] }],\n    }) as Promise<string>;\n  }\n\n  async generateTextWithBase64Image(\n    generateImageBase64Dto: GenerateImageBase64Dto,\n  ): Promise<string> {\n    const { base64Image, mimeType } = generateImageBase64Dto;\n    return this._performGeminiOperation({\n      dto: generateImageBase64Dto,\n      requestType: RequestType.TEXT_WITH_IMAGE,\n      getContents: (dto) => [\n        {\n          role: 'user',\n          parts: [\n            { text: dto.prompt },\n            {\n              inlineData: {\n                mime_type: dto.mimeType,\n                data: dto.base64Image,\n              },\n            },\n          ],\n        },\n      ],\n      saveOptions: { imageData: base64Image, fileMimeType: mimeType },\n    }) as Promise<string>;\n  }\n\n  // Adjusted this method to process Multer.File internally before calling the common helper.\n  // This keeps the external API (`prompt: string, file: Express.Multer.File`) consistent.\n  async generateTextWithFile(\n    prompt: string,\n    file: Express.Multer.File,\n    systemInstruction?: string,\n    conversationId?: string,\n  ): Promise<string> {\n    if (!file) {\n      throw new BadRequestException('No file provided for analysis.');\n    }\n    this.logger.debug(`generateTextWithFile called with conversationId: ${conversationId}, filename: ${file.originalname}`);\n\n    const base64Data = file.buffer.toString('base64');\n    const fileName = file.originalname;\n    // More robust MIME type lookup\n    const fileMimeType = file.mimetype || mimeLookup(fileName) || 'application/octet-stream';\n\n    const dto: GenerateFileInternalDto = {\n      prompt,\n      systemInstruction,\n      conversationId,\n      base64Data,\n      mimeType: fileMimeType,\n    };\n\n    return this._performGeminiOperation({\n      dto: dto,\n      requestType: RequestType.TEXT_WITH_FILE,\n      getContents: (internalDto) => [\n        {\n          role: 'user',\n          parts: [\n            { text: internalDto.prompt },\n            {\n              inlineData: {\n                mime_type: internalDto.mimeType,\n                data: internalDto.base64Data,\n              },\n            },\n          ],\n        },\n      ],\n      saveOptions: { fileData: base64Data, fileMimeType: fileMimeType },\n    }) as Promise<string>;\n  }\n\n  /**\n   * Generates a resume based on a detailed prompt.\n   * @param generateResumeDto DTO containing prompt for resume generation.\n   * @returns The generated resume text.\n   */\n  async generateResume(generateResumeDto: GenerateResumeDto): Promise<string> {\n    const defaultSystemInstruction = `You are an expert resume writer. Generate a professional and comprehensive resume in Markdown format based on the user's requirements. Ensure proper headings, bullet points for experience/achievements, and appropriate sections (e.g., Summary, Experience, Education, Skills, Projects). Focus on clarity, conciseness, and impact. Do not include any introductory or concluding remarks outside the resume itself.\n\nFollow this markdown format:\n---\nname: Alex Techpro\nemail: alex.techpro@example.com\nphone: +1 (555) 987-6543\nlinkedin: linkedin.com/in/alex-techpro-senior-swe\ngithub: github.com/alextechpro-dev\nlocation: New York, NY\n---\n\n# Alex Techpro\n\n## Summary\n\nHighly accomplished Senior Software Engineer with **10 years of experience** designing, developing, and deploying robust, scalable, and high-performance full-stack applications. Proven expertise in **TypeScript, React, Node.js, and AWS**, with a strong focus on building critical systems in the **FinTech domain**. Adept at leading complex projects, optimizing system architecture, and delivering innovative solutions that drive business growth and operational efficiency. Seeking to leverage advanced technical skills and leadership capabilities to contribute to a forward-thinking FinTech organization.\n\n## Experience\n\n**Senior Software Engineer** | InnovateFin Solutions | New York, NY\nJanuary 2020 – Present\n\n*   Led the design and implementation of a real-time trading platform using React, Node.js, and AWS Lambda, processing over **1 million transactions daily**.\n*   Architected and developed microservices for financial data aggregation and analytics using TypeScript, Node.js, and AWS DynamoDB, ensuring high availability and fault tolerance.\n*   Mentored junior engineers, conducted code reviews, and fostered best practices in CI/CD, testing, and system design within an Agile/Scrum environment.\n*   Collaborated cross-functionally with product and quantitative analysts to translate complex financial requirements into technical specifications.\n*   **Reduced transaction latency by 40%** (from 250ms to 150ms) by optimizing WebSocket communication and API Gateway configurations.\n*   **Improved data processing efficiency by 30%** and **reduced cloud infrastructure costs by 20%** through refactoring legacy Node.js services to serverless AWS Lambda functions.\n*   Developed and launched a new user-facing dashboard for portfolio management, **increasing user engagement by 25%** within the first 3 months.\n*   Successfully led the migration of a monolithic payment processing system to a microservices architecture, **improving system scalability by 5x**.\n\n**Software Engineer** | WealthFlow Technologies | New York, NY\nJuly 2016 – December 2019\n\n*   Developed and maintained critical components of a wealth management platform, focusing on client onboarding and investment tracking modules.\n*   Built robust RESTful APIs using Node.js and Express.js, integrating with third-party financial services APIs (e.g., market data feeds, payment processors).\n*   Implemented responsive and intuitive user interfaces with React and Redux, ensuring a seamless user experience for financial advisors and clients.\n*   Participated in the design and implementation of PostgreSQL database schemas and optimized complex SQL queries for financial reporting.\n*   Contributed to the development of a new client onboarding portal, **reducing manual processing time by 35%** and improving data accuracy.\n*   Enhanced system monitoring and alerting with AWS CloudWatch, **decreasing incident response time by 20%** and improving system stability.\n*   **Improved application performance by optimizing React component rendering** and state management, leading to a 15% faster page load time.\n*   Played a key role in integrating a new payment gateway, enabling support for three additional payment methods and expanding market reach.\n\n**Junior Software Engineer** | FinEdge Solutions | Boston, MA\nJune 2014 – June 2016\n\n*   Developed frontend features for an internal CRM system using JavaScript (ES6) and early React.js, focusing on client relationship management in finance.\n*   Assisted in backend development for data synchronization services using Node.js for financial record keeping.\n*   Contributed to testing efforts, including unit and integration tests, ensuring data integrity for financial transactions.\n*   Participated in daily stand-ups and sprint planning sessions within an Agile environment.\n*   Implemented a new data visualization module, providing real-time insights into customer engagement and financial trends.\n*   Automated routine data entry tasks using scripting, **saving approximately 5 hours of manual work per week**.\n*   Successfully migrated legacy JavaScript components to a React-based framework, improving maintainability and development velocity.\n\n## Education\n\n**Master of Science in Computer Science** | Columbia University | New York, NY\nSeptember 2015 – May 2017\n*   Specialization in Software Systems and Data Engineering\n\n**Bachelor of Science in Computer Engineering** | Northeastern University | Boston, MA\nSeptember 2010 – May 2014\n*   Graduated Magna Cum Laude\n*   Relevant Coursework: Data Structures, Algorithms, Distributed Systems, Database Management\n\n## Skills\n\n**Programming Languages:** TypeScript, JavaScript (ES6+), Python, SQL\n**Frontend:** React.js, Redux, Next.js, HTML5, CSS3 (Sass/Less), Webpack, Vite\n**Backend:** Node.js, Express.js, NestJS, RESTful APIs, GraphQL, Microservices, Serverless Architectures\n**Cloud Platforms:** AWS (EC2, Lambda, S3, RDS, DynamoDB, SQS, SNS, API Gateway, CloudWatch, VPC, IAM, Cognito, ECS/EKS)\n**Databases:** PostgreSQL, MongoDB, DynamoDB, Redis, MySQL\n**DevOps & Tools:** Docker, Kubernetes (basic), Jenkins, CircleCI, GitHub Actions, Git, Jira, Confluence, Agile/Scrum\n**Testing:** Jest, React Testing Library, Cypress, Mocha, Chai, Supertest\n**FinTech Domain:** High-Frequency Trading Systems, Payment Processing, Market Data Systems, Regulatory Compliance (e.g., PCI DSS, GDPR concepts), Algorithmic Trading Concepts, Wealth Management Platforms, Quantitative Finance Principles\n`;\n\n    return this._performGeminiOperation({\n      dto: generateResumeDto,\n      requestType: RequestType.RESUME_GENERATION, // Specific enum for this task\n      getContents: (dto) => [{ role: 'user', parts: [{ text: dto.prompt }] }],\n      defaultSystemInstruction: defaultSystemInstruction,\n    }) as Promise<string>;\n  }\n\n  /**\n   * Optimizes a resume based on a job description, returning structured suggestions.\n   * @param optimizeResumeDto DTO containing resume content and job description.\n   * @returns An object with optimization score, summary, and detailed suggestions.\n   */\n  async optimizeResume(optimizeResumeDto: OptimizeResumeDto): Promise<OptimizationResultDto> {\n    const defaultSystemInstruction = `You are an AI resume optimization expert. Your task is to analyze a given resume against a job description and provide actionable, specific suggestions to improve its alignment. Focus on:\n- Keyword matching (hard skills, soft skills, industry terms)\n- Quantifiable achievements and impact\n- Use of strong action verbs\n- Overall relevance and conciseness\n- Identifying gaps or areas for improvement.\n\nReturn your response as a JSON object strictly adhering to the following TypeScript interface. Do NOT include any other text or formatting outside the JSON block.\n\ninterface OptimizationSuggestion {\n  type: string; // e.g., \"Keyword Match\", \"Action Verbs\", \"Quantifiable Achievements\", \"Relevance\", \"Formatting\"\n  recommendation: string; // A concise recommendation\n  details?: string[]; // Specific points or examples from the resume/JD to support the recommendation\n}\n\ninterface OptimizationResult {\n  optimizationScore: number; // A score (e.g., out of 100) indicating alignment\n  tailoredSummary: string; // A brief, overall summary of alignment and key takeaways\n  suggestions: OptimizationSuggestion[]; // Array of detailed suggestions\n  improvedResumeSection?: string; // Optional: A small, rewritten example section for demonstration\n}\n\nEnsure the JSON is perfectly parsable. If no specific suggestion for a category, omit it or provide an empty array.\n`;\n    const prompt = `Here is the resume:\\n\\n${optimizeResumeDto.resumeContent}\\n\\nHere is the job description:\\n\\n${optimizeResumeDto.jobDescription}\\n\\nBased on these, generate the optimization result in the specified JSON format.`;\n\n    return this._performGeminiOperation({\n      dto: { ...optimizeResumeDto, prompt: prompt }, // Override prompt for internal use\n      requestType: RequestType.RESUME_OPTIMIZATION, // Specific enum for this task\n      getContents: (dto) => [{ role: 'user', parts: [{ text: dto.prompt }] }],\n      defaultSystemInstruction: defaultSystemInstruction,\n      parseResult: (generatedText: string): OptimizationResultDto => {\n        try {\n          // Gemini might wrap JSON in markdown code block, try to extract it\n          const jsonMatch = generatedText.match(/```json\\n([\\s\\S]*?)\\n```/);\n          const jsonString = jsonMatch ? jsonMatch[1] : generatedText;\n          return JSON.parse(jsonString);\n        } catch (jsonError) {\n          this.logger.error(`Failed to parse Gemini JSON response for resume optimization: ${jsonError.message}`);\n          this.logger.error(`Raw Gemini response (optimization): ${generatedText}`);\n          throw new InternalServerErrorException('Gemini returned an unparseable JSON response for resume optimization.');\n        }\n      },\n    }) as Promise<OptimizationResultDto>;\n  }\n\n  /**\n   * Enhances a given resume content or a specific section based on a goal.\n   * @param enhanceResumeDto DTO containing resume content, optional section, and enhancement goal.\n   * @returns The enhanced resume text or section.\n   */\n  async enhanceResume(enhanceResumeDto: EnhanceResumeDto): Promise<string> {\n    let defaultSystemInstruction = `You are an expert resume enhancer. Your goal is to rewrite or improve the provided resume content to be more impactful, concise, and professional. Focus on strong action verbs, quantifiable achievements, and clear communication. Do not add or remove factual information unless explicitly instructed. Provide only the enhanced text, with no additional commentary.`;\n    if (enhanceResumeDto.sectionToEnhance) {\n      defaultSystemInstruction += ` Specifically focus on enhancing the '${enhanceResumeDto.sectionToEnhance}' section.`;\n    }\n    if (enhanceResumeDto.enhancementGoal) {\n      defaultSystemInstruction += ` The specific goal for enhancement is: '${enhanceResumeDto.enhancementGoal}'.`;\n    }\n\n    const prompt = enhanceResumeDto.sectionToEnhance\n      ? `Enhance the '${enhanceResumeDto.sectionToEnhance}' section of the following resume. The original resume content is:\\n\\n${enhanceResumeDto.resumeContent}`\n      : `Enhance the following resume content:\\n\\n${enhanceResumeDto.resumeContent}`;\n\n    return this._performGeminiOperation({\n      dto: { ...enhanceResumeDto, prompt: prompt }, // Override prompt for internal use\n      requestType: RequestType.RESUME_ENHANCEMENT, // Specific enum for this task\n      getContents: (dto) => [{ role: 'user', parts: [{ text: dto.prompt }] }],\n      defaultSystemInstruction: defaultSystemInstruction,\n    }) as Promise<string>;\n  }\n}\n\n\n\n// File: ../../full-stack/src/google/google-gemini/google-gemini-file/dto/enhance-resume.dto.ts\n// src/google/google-gemini/google-gemini-file/dto/enhance-resume.dto.ts\nimport { IsString, IsNotEmpty, IsOptional, IsUUID } from 'class-validator';\nimport { ApiProperty } from '@nestjs/swagger'; // Import ApiProperty\n\nexport class EnhanceResumeDto {\n  @ApiProperty({\n    description: 'The full plain text content of the resume to be enhanced.',\n    example: 'John Doe\\nSoftware Engineer\\nExperience:\\n- Developed X using Y...\\nSkills: Z',\n    minLength: 1, // Reflects IsNotEmpty validation\n  })\n  @IsString()\n  @IsNotEmpty()\n  resumeContent: string; // The full resume text\n\n  @ApiProperty({\n    description: 'Optional: A specific section of the resume to focus the enhancement on (e.g., \"summary\", \"experience\", \"skills\").',\n    example: 'Experience',\n    required: false,\n  })\n  @IsOptional()\n  @IsString()\n  sectionToEnhance?: string; // e.g., \"summary\", \"experience\", \"skills\" - helps AI focus\n\n  @ApiProperty({\n    description: 'Optional: A specific goal or instruction for the enhancement (e.g., \"make more concise\", \"add metrics\", \"target leadership roles\").',\n    example: 'Make the experience section more action-oriented with quantifiable results.',\n    required: false,\n  })\n  @IsOptional()\n  @IsString()\n  enhancementGoal?: string; // Specific goal, e.g., \"make more concise\", \"add metrics\", \"target leadership\"\n\n  @ApiProperty({\n    description: 'Optional: Custom system instruction to guide the AI model for nuanced enhancement requests. Overrides default instructions.',\n    example: 'Ensure all bullet points start with strong action verbs and highlight agile methodologies.',\n    required: false,\n  })\n  @IsOptional()\n  @IsString()\n  systemInstruction?: string; // Custom system instruction for specific enhancement nuances\n\n  @ApiProperty({\n    description: 'Optional: An existing conversation ID to maintain context with the AI model for continued interaction.',\n    example: 'a1b2c3d4-e5f6-7890-1234-567890abcdef',\n    required: false,\n  })\n  @IsOptional()\n  @IsUUID()\n  conversationId?: string;\n}\n\n\n\n// File: ../../full-stack/src/google/google-gemini/google-gemini-file/dto/generate-file.dto.ts\nimport { ApiProperty } from '@nestjs/swagger';\nimport { IsString, IsNotEmpty, IsOptional, IsUUID } from 'class-validator';\n\nexport class GenerateFileDto {\n  @ApiProperty({\n    description: 'The text prompt for Gemini.',\n    example: 'Analyze this SQL schema and suggest improvements.',\n  })\n  @IsString()\n  @IsNotEmpty()\n  prompt: string;\n\n  @ApiProperty({\n    description:\n      \"Optional system instruction to guide the model's behavior (e.g., persona or style). If provided for a new conversation, it will be used for subsequent requests in that conversation.\",\n    example: 'Explain this code line by line.',\n    required: false,\n  })\n  @IsString()\n  @IsOptional()\n  systemInstruction?: string;\n\n  @ApiProperty({\n    description:\n      'Optional ID of an ongoing conversation. If provided, the system instruction from the first request in this conversation will be used.',\n    example: 'a1b2c3d4-e5f6-7890-1234-567890abcdef',\n    required: false,\n  })\n  @IsString()\n  @IsOptional()\n  @IsUUID()\n  conversationId?: string; // New optional field\n}\n\n\n// File: ../../full-stack/src/google/google-gemini/google-gemini-file/dto/generate-image-base64.dto.ts\nimport { ApiProperty } from '@nestjs/swagger';\nimport {\n  IsString,\n  IsNotEmpty,\n  IsOptional,\n  IsMimeType,\n  IsBase64,\n  IsUUID,\n} from 'class-validator';\n\nexport class GenerateImageBase64Dto {\n  @ApiProperty({\n    description: 'The prompt text to accompany the image.',\n    example: 'Describe this image.',\n  })\n  @IsString()\n  @IsNotEmpty()\n  prompt: string;\n\n  @ApiProperty({\n    description:\n      'The Base64 encoded image data (without \"data:image/jpeg;base64,\" prefix).',\n    example:\n      'iVBORw0KGgoAAAANSUhEUgAAAAUAAAAFCAYAAACNbyblAAAAHElEQVQI12P4//8/w38GIAXDIBKE0DHxgljNBAAO9TXL0Y4OHwAAAABJRU5ErkJggg==',\n  })\n  @IsString()\n  @IsNotEmpty()\n  @IsBase64()\n  base64Image: string;\n\n  @ApiProperty({\n    description:\n      'The MIME type of the image (e.g., \"image/jpeg\", \"image/png\").',\n    example: 'image/jpeg',\n  })\n  @IsString()\n  @IsNotEmpty()\n  @IsMimeType()\n  mimeType: string;\n\n  @ApiProperty({\n    description:\n      \"Optional system instruction to guide the model's behavior (e.g., persona or style). If provided for a new conversation, it will be used for subsequent requests in that conversation.\",\n    example: 'Analyze this image from a botanical perspective.',\n    required: false,\n  })\n  @IsString()\n  @IsOptional()\n  systemInstruction?: string;\n\n  @ApiProperty({\n    description:\n      'Optional ID of an ongoing conversation. If provided, the system instruction from the first request in this conversation will be used.',\n    example: 'a1b2c3d4-e5f6-7890-1234-567890abcdef',\n    required: false,\n  })\n  @IsString()\n  @IsOptional()\n  @IsUUID()\n  conversationId?: string; // New optional field\n}\n\n\n// File: ../../full-stack/src/google/google-gemini/google-gemini-file/dto/generate-resume.dto.ts\n// src/google/google-gemini/google-gemini-file/dto/generate-resume.dto.ts\nimport { IsString, IsNotEmpty, IsOptional, IsUUID } from 'class-validator';\nimport { ApiProperty } from '@nestjs/swagger'; // Import ApiProperty\n\nexport class GenerateResumeDto {\n  @ApiProperty({\n    description: 'The detailed prompt describing the resume to be generated. This should include personal details, desired job role, experience level, key skills, and any specific sections or formatting requirements.',\n    example: 'Generate a resume for a senior software engineer with 10 years of experience in TypeScript, React, Node.js, and AWS. Include a strong summary, a detailed experience section with quantifiable achievements, education, and a skills section. Target roles in FinTech.',\n    minLength: 1, // Reflects IsNotEmpty validation\n  })\n  @IsString()\n  @IsNotEmpty()\n  prompt: string;\n\n  @ApiProperty({\n    description: 'Optional: Custom system instruction to guide the AI model on how to generate the resume (e.g., \"Use a modern, minimalist design\", \"Focus on leadership experience\"). Overrides default instructions.',\n    example: 'Generate the resume strictly in JSON format, outlining each section as a separate object.',\n    required: false,\n  })\n  @IsOptional()\n  @IsString()\n  systemInstruction?: string;\n\n  @ApiProperty({\n    description: 'Optional: An existing conversation ID to maintain context with the AI model for continued interaction (e.g., if refining a previously generated resume).',\n    example: 'a1b2c3d4-e5f6-7890-1234-567890abcdef',\n    required: false,\n  })\n  @IsOptional()\n  @IsUUID()\n  conversationId?: string;\n}\n\n\n\n// File: ../../full-stack/src/google/google-gemini/google-gemini-file/dto/generate-text.dto.ts\nimport { ApiProperty } from '@nestjs/swagger';\nimport { IsString, IsNotEmpty, IsOptional, IsUUID } from 'class-validator';\n\nexport class GenerateTextDto {\n  @ApiProperty({\n    description: 'The prompt text to send to the Gemini model.',\n    example: 'Write a short story about a brave knight.',\n  })\n  @IsString()\n  @IsNotEmpty()\n  prompt: string;\n\n  @ApiProperty({\n    description:\n      \"Optional system instruction to guide the model's behavior (e.g., persona or style). If provided for a new conversation, it will be used for subsequent requests in that conversation.\",\n    example:\n      'Act as a seasoned cybersecurity expert and explain common phishing techniques.',\n    required: false,\n  })\n  @IsString()\n  @IsOptional()\n  systemInstruction?: string;\n\n  @ApiProperty({\n    description:\n      'Optional ID of an ongoing conversation. If provided, the system instruction from the first request in this conversation will be used.',\n    example: 'a1b2c3d4-e5f6-7890-1234-567890abcdef',\n    required: false,\n  })\n  @IsString()\n  @IsOptional()\n  @IsUUID()\n  conversationId?: string; // New optional field\n}\n\n\n// File: ../../full-stack/src/google/google-gemini/google-gemini-file/dto/index.ts\nexport { GenerateTextDto } from './generate-text.dto';\nexport { GenerateImageBase64Dto } from './generate-image-base64.dto';\nexport { GenerateFileDto } from './generate-file.dto';\n\nexport { OptimizeResumeDto } from './optimize-resume.dto';\nexport { GenerateResumeDto } from './generate-resume.dto';\nexport { OptimizationSuggestionDto, OptimizationResultDto } from './optimization-result.dto';\nexport { EnhanceResumeDto } from './enhance-resume.dto';\n\n\n\n\n// File: ../../full-stack/src/google/google-gemini/google-gemini-file/dto/optimization-result.dto.ts\n// src/google-gemini/dto/optimization-result.dto.ts (Response DTO)\n// This mirrors the frontend's expected structure\nexport class OptimizationSuggestionDto {\n  type: string;\n  recommendation: string;\n  details?: string[];\n}\n\nexport class OptimizationResultDto {\n  optimizationScore: number;\n  tailoredSummary: string;\n  suggestions: OptimizationSuggestionDto[];\n  improvedResumeSection?: string; // Optional, AI might return a rewritten section\n  conversationId?: string;\n}\n\n\n// File: ../../full-stack/src/google/google-gemini/google-gemini-file/dto/optimize-resume.dto.ts\n// src/google-gemini/dto/optimize-resume.dto.ts\nimport { IsString, IsNotEmpty, IsOptional, IsUUID } from 'class-validator';\n\nexport class OptimizeResumeDto {\n  @IsString()\n  @IsNotEmpty()\n  resumeContent: string;\n\n  @IsString()\n  @IsNotEmpty()\n  jobDescription: string;\n\n  @IsOptional()\n  @IsString()\n  systemInstruction?: string; // Custom system instruction for specific optimization nuances\n\n  @IsOptional()\n  @IsUUID()\n  conversationId?: string;\n}\n\n// File: ../../full-stack/src/google/google-gemini/google-gemini-file/enum/google-gemini-file.enum.ts\nexport enum RequestType {\n  TEXT_ONLY = 'TEXT_ONLY',\n  TEXT_WITH_IMAGE = 'TEXT_WITH_IMAGE',\n  TEXT_WITH_FILE = 'TEXT_WITH_FILE',\n  RESUME_GENERATION = 'RESUME_GENERATION',\n  RESUME_OPTIMIZATION = 'RESUME_OPTIMIZATION',\n  RESUME_ENHANCEMENT = 'RESUME_ENHANCEMENT',\n}\n\n\n// File: ../../full-stack/src/google/google-gemini/google-gemini-file/interfaces/generate-file.interface.ts\n// src/gemini/interfaces/generate-file.interface.ts\nexport interface IGenerateFile {\n  prompt: string;\n  // File handled via Multer (not part of interface)\n}\n\n\n// File: ../../full-stack/src/google/google-gemini/google-gemini-file/interfaces/generate-image-base64.interface.ts\n// src/gemini/interfaces/generate-image-base64.interface.ts\nexport interface IGenerateImageBase64 {\n  prompt: string;\n  base64Image: string;\n  mimeType: string;\n}\n\n\n// File: ../../full-stack/src/google/google-gemini/google-gemini-file/interfaces/generate-text.interface.ts\n// src/gemini/interfaces/generate-text.interface.ts\nexport interface IGenerateText {\n  prompt: string;\n}\n\n\n// File: src/llm/contextPreparer.ts\n// src/llm/contextPreparer.ts\nimport * as path from 'path';\nimport { ScannedFile, LLMInput } from '../types';\n\n/**\n * Prepares the context for the LLM by structuring the user prompt,\n * relevant files, and system instructions into a single LLMInput object.\n *\n * @param userPrompt The natural language request from the user.\n * @param scannedFiles An array of all files scanned from the project.\n * @param projectRoot The absolute path to the project's root directory.\n * @returns An LLMInput object ready to be sent to the LLM.\n */\nexport function prepareContextForLLM(userPrompt: string, scannedFiles: ScannedFile[], projectRoot: string): LLMInput {\n\n  // 1. Generate a simplified project structure string using relative paths\n  const projectStructureLines = scannedFiles\n    .map(file => file.relativePath) // Use the relativePath from ScannedFile\n    .sort()\n    .map(relPath => `- ${relPath}`);\n\n  const projectStructure = `Project File Structure (relative to root):\\n${projectStructureLines.join('\\n')}\\n`;\n\n  // 2. Define the expected output format for the LLM\n  const outputSchema = `\n            Your response must be a JSON object with two top-level keys: 'summary' (string) and 'changes' (array of objects).\n            The 'changes' array should contain objects, each representing a file operation:\n            {\n              \"filePath\": \"path/to/file.tsx\", // Absolute path (use path.join(projectRoot, relativePath) to construct)\n              \"action\": \"add\" | \"modify\" | \"delete\",\n              \"newContent\"?: \"...\", // Required for 'add'/'modify', omit for 'delete'\n              \"reason\"?: \"...\" // Optional, short explanation for this specific file change\n            }\n            Example:\n            {\n              \"summary\": \"Implemented user authentication and updated Navbar component.\",\n              \"thoughtProcess\": \"Created new components for login and signup, updated navigation to include auth links, and added a basic auth context.\",\n              \"changes\": [\n                {\n                  \"filePath\": \"/path/to/project/src/auth/Login.tsx\",\n                  \"action\": \"add\",\n                  \"newContent\": \"import React from 'react';\\\\nimport { useStore } from '@nanostores/react';\\\\nimport { authStore } from './authStore';\\\\n\\\\nfunction Login() {\\\\n  const $auth = useStore(authStore);\\\\n  // ... login form logic\\\\n  return <div className='p-4'>Login Form</div>;\\\\n}\\\\nexport default Login;\",\n                  \"reason\": \"New login component for user authentication.\"\n                },\n                {\n                  \"filePath\": \"/path/to/project/src/components/Navbar.tsx\",\n                  \"action\": \"modify\",\n                  \"newContent\": \"import React from 'react';\\\\nimport { Link } from 'react-router-dom';\\\\nimport { useStore } from '@nanostores/react';\\\\nimport { authStore } from '../auth/authStore';\\\\n\\\\nfunction Navbar() {\\\\n  const $auth = useStore(authStore);\\\\n  return (\\\\n    <nav className='bg-blue-500 p-4 text-white flex justify-between'>\\\\n      <Link to='/' className='font-bold text-lg'>My App</Link>\\\\n      <div>\\\\n        {$auth.isLoggedIn ? (\\\\n          <button onClick={() => authStore.setKey('isLoggedIn', false)} className='ml-4'>Logout</button>\\\\n        ) : (\\\\n          <>\\\\n            <Link to='/login' className='ml-4'>Login</Link>\\\\n            <Link to='/signup' className='ml-4'>Signup</Link>\\\\n          </>\\\\n        )}\\\\n      </div>\\\\n    </nav>\\\\n  );\\\\n}\\\\nexport default Navbar;\",\n                  \"reason\": \"Added login/logout links to Navbar based on authentication status.\"\n                },\n                {\n                  \"filePath\": \"/path/to/project/src/old/DeprecatedComponent.ts\",\n                  \"action\": \"delete\",\n                  \"reason\": \"Removed unused component as part of refactor.\"\n                }\n              ]\n            }\n          `.replace(/^\\s+/gm, '');\n\n  // 3. Construct additional instructions for the LLM\n  const additionalInstructions = `\nYou are an elite TypeSafe UI Architect. Your goal is to generate or modify code to fulfill the user's request, strictly adhering to modern frontend best practices.\nFocus on TypeScript, React (with Hooks and nanostores where applicable), and Tailwind CSS v4.\nGenerate clean, idiomatic, production-ready code.\nAlways propose a clear, refactored, and logically separated file and folder structure.\nConsider type safety paramount.\nIf the request involves new components, ensure they are well-structured, reusable, and include necessary imports and typings.\nIf modifying existing components, ensure backward compatibility where reasonable, or clearly state breaking changes.\nWhen generating new code, ensure it aligns with the existing project's style (indentation, semicolons, etc.).\nDo not make assumptions about external APIs unless specified.\nIf you need to add a new file, propose the full content of that new file.\nIf you need to modify an existing file, propose the full new content of that file.\nIf you need to delete a file, specify its path and action 'delete'.\n`;\n\n  return {\n    userPrompt: userPrompt,\n    projectRoot: projectRoot,\n    projectStructure: projectStructure,\n    relevantFiles: scannedFiles,\n    additionalInstructions: additionalInstructions,\n    expectedOutputFormat: outputSchema,\n  };\n}\n\n/**\n * This function will construct the final prompt string that is sent to the LLM.\n * This combines all parts of the LLMInput into a single markdown-formatted string.\n * @param llmInput The structured input object.\n * @param projectRoot The project root (passed to ensure consistency, but `llmInput.projectRoot` is the primary source).\n * @returns A string representing the full prompt for the LLM.\n */\nexport function buildLLMPrompt(llmInput: LLMInput, projectRoot: string): string {\n  // Use `file.relativePath` from `scannedFiles` for the prompt, as it's cleaner for LLM context.\n  const formattedRelevantFiles = llmInput.relevantFiles.map(file => {\n    return `// File: ${file.relativePath}\\n${file.content}`;\n  }).join('\\n\\n'); // Separate files with double newlines\n\n  return `\n# AI Code Generation Request\n\n## User Request\n\\`\\`\\`text\n${llmInput.userPrompt}\n\\`\\`\\`\n\n## Project Context\n${llmInput.projectStructure}\n\n### Relevant Files (for analysis)\n\\`\\`\\`files\n${formattedRelevantFiles}\n\\`\\`\\`\n`;\n}\n\n\n// File: src/llm/jsonRepair.ts\n// src/llm/jsonRepair.ts\n\n/**\n * Attempts to repair common bad escape sequences in a JSON string\n * that might be returned by an LLM.\n * This function primarily focuses on fixing lone backslashes within string values\n * that cause JSON parsing errors.\n *\n * It is assumed that the LLM, when instructed to return JSON (e.g., with responseMimeType: \"application/json\"),\n * generally handles standard string escapes like `\\n`, `\\t`, `\\\"` correctly.\n * This repair function is a fallback for common minor deviations, mainly malformed backslashes.\n *\n * @param jsonString The potentially malformed JSON string.\n * @returns A repaired JSON string, or the original string if no repairs were made.\n */\nexport function repairJsonBadEscapes(jsonString: string): string {\n  let repaired = jsonString;\n\n  // IMPORTANT: Removed the replacement for unescaped newlines/tabs/carriage returns.\n  // These replacements (e.g., `/(?<!\\\\)\\n/g, '\\\\n'`) were incorrectly converting\n  // structural newlines (used for JSON pretty-printing) into escaped newlines (`\\n` -> `\\\\n`),\n  // which makes the JSON invalid at the structural level.\n  // JSON parsers expect literal newlines/tabs for formatting outside of string literals.\n  // If a newline is inside a string value, the LLM should already be providing `\\\\n`.\n\n  // 1. Escape lone backslashes that are not part of a valid JSON escape sequence.\n  // This regex targets backslashes not followed by another backslash or a standard JSON escape char.\n  // Example: \"C:\\path\\to\\file\" should become \"C:\\\\path\\\\to\\\\file\"\n  // The `(?!...)` is a negative lookahead, ensuring the backslash is not followed by\n  // a valid JSON escape character (\", \\, /, b, f, n, r, t, u (for unicode escapes)).\n  // This is the most common and relatively safe repair for paths or other literal backslashes within string values.\n  repaired = repaired.replace(/\\\\(?![\"\\\\/bfnrtu])/g, '\\\\\\\\');\n\n  return repaired; // Return the repaired string\n}\n\n\n// File: src/llm/llmOrchestrator.ts\nimport { promises as fs } from 'fs';\nimport * as path from 'path';\nimport { GoogleGenerativeAI, HarmCategory, HarmBlockThreshold } from '@google/generative-ai';\nimport { LLMInput, LLMOutput, ProposedFileChange } from '../types';\nimport { buildLLMPrompt } from './contextPreparer';\nimport { repairJsonBadEscapes } from './jsonRepair';\n\n// Access your API key (ensure dotenv is configured in index.ts)\nconst API_KEY = process.env.GOOGLE_GEMINI_API_KEY;\nconst MODEL = process.env.GOOGLE_GEMINI_MODEL || 'gemini-1.5-pro-latest'; // Added a default model for robustness\n\nif (!API_KEY) {\n  console.error('Error: GOOGLE_GEMINI_API_KEY environment variable not set.');\n  console.error('Please create a .env file in the project root with GOOGLE_GEMINI_API_KEY=\"YOUR_API_KEY\".');\n  process.exit(1);\n}\n\nconst genAI = new GoogleGenerativeAI(API_KEY);\n\n// Choose a model. Gemini 1.5 Pro is generally good for coding.\nconst model = genAI.getGenerativeModel({ model: MODEL });\n\n// Safety settings to ensure generated content is appropriate\nconst safetySettings = [\n  {\n    category: HarmCategory.HARM_CATEGORY_HARASSMENT,\n    threshold: HarmBlockThreshold.BLOCK_NONE, // Adjust as needed, BLOCK_NONE can lead to more candid responses, but potentially harmful ones. BLOCK_LOW_AND_ABOVE is safer default.\n  },\n  {\n    category: HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n    threshold: HarmBlockThreshold.BLOCK_NONE,\n  },\n  {\n    category: HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n    threshold: HarmBlockThreshold.BLOCK_NONE,\n  },\n  {\n    category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n    threshold: HarmBlockThreshold.BLOCK_NONE,\n  },\n];\nconst LOGS_DIR = path.join(process.cwd(), '.ai-editor-logs'); // Logs directory at project root\n\n/**\n * Saves the raw text response from the LLM to a timestamped JSON file.\n * The file is saved in a `.ai-editor-logs` directory at the project root.\n * @param rawText The raw string response from the LLM.\n * @param prompt The original prompt sent to the LLM (for context in the log file).\n */\nasync function saveRawLLMResponse(rawText: string, prompt: string): Promise<void> {\n  try {\n    await fs.mkdir(LOGS_DIR, { recursive: true }); // Ensure log directory exists\n\n    const timestamp = new Date().toISOString().replace(/[:.]/g, '-'); // YYYY-MM-DDTHH-MM-SS-MSZ\n    const fileName = `llm-response-${timestamp}.json`; // Using .json as it's expected to be JSON\n    const filePath = path.join(LOGS_DIR, fileName);\n\n    const logContent = {\n      timestamp: new Date().toISOString(),\n      prompt: prompt,\n      // Attempt to parse if it's JSON, otherwise store as string for better logging\n      rawLLMResponse: (() => {\n        try {\n          return JSON.parse(rawText);\n        } catch {\n          return rawText;\n        }\n      })(),\n    };\n\n    await fs.writeFile(filePath, JSON.stringify(logContent, null, 2), 'utf-8');\n    console.log(`  📝 Saved raw LLM response to: ${path.relative(process.cwd(), filePath)}`);\n  } catch (error) {\n    console.error(`  ❌ Error saving raw LLM response to file: ${(error as Error).message}`);\n  }\n}\n/**\n * Extracts a JSON string from text that might be wrapped in markdown code blocks.\n * This makes parsing more robust against LLM formatting variations.\n * @param text The raw text from the LLM.\n * @returns The extracted JSON string, or the original text if no JSON block is found.\n */\nfunction extractJsonFromMarkdown(text: string): string {\n    const jsonBlockRegex = /```json\\n([\\s\\S]*?)\\n```/;\n    const match = text.match(jsonBlockRegex);\n    if (match && match[1]) {\n        return match[1].trim();\n    }\n    // If it's not wrapped in a JSON block, assume it's pure JSON and just trim it.\n    return text.trim();\n}\n\n/**\n * Calls the Google Gemini LLM API and processes the structured JSON response.\n *\n * @param input The structured LLMInput object.\n * @returns A promise that resolves to the LLMOutput.\n */\nexport async function callLLM(input: LLMInput, projectRoot: string): Promise<LLMOutput> {\n  const fullPrompt = buildLLMPrompt(input, projectRoot);\n  // This constructs the system instruction based on the LLMInput\n  const systemInstruction = `${input.additionalInstructions}\\n\\n${input.expectedOutputFormat}`;\n\n  console.log('\\n--- Prompt sent to LLM ---');\n  // console.log(fullPrompt); // Uncomment for debugging the full prompt\n  console.log(`Prompt size: ${fullPrompt.length} characters.`);\n  console.log('--------------------------\\n');\n\n  try {\n    const result = await model.generateContent({\n      contents: [{ role: \"user\", parts: [{ text: fullPrompt }] }],\n      // UNCOMMENT THIS LINE TO ADD SYSTEM INSTRUCTION\n      systemInstruction: {role: \"system\",  parts: [{ text: systemInstruction }]},\n      safetySettings,\n      generationConfig: {\n        responseMimeType: \"application/json\",\n      },\n    });\n\n    const response = result.response;\n    let rawText = response.text();\n\n    // Save raw LLM response for debugging and auditing\n    await saveRawLLMResponse(rawText, fullPrompt);\n\n    console.log('\\n--- Raw LLM Response ---');\n    console.log(rawText);\n    console.log('------------------------\\n');\n\n    let cleanedJsonString = extractJsonFromMarkdown(rawText);\n\n    let parsedResult: any; // Use 'any' initially as the top-level structure might vary\n    try {\n      parsedResult = JSON.parse(cleanedJsonString);\n    } catch (jsonError) {\n      console.warn('Warning: Initial JSON parsing failed. Attempting to repair bad escaped characters.');\n      try {\n        const repairedJsonString = repairJsonBadEscapes(cleanedJsonString);\n        parsedResult = JSON.parse(repairedJsonString);\n        console.log('JSON parsing succeeded after repair.');\n      } catch (repairError) {\n        console.error('Error parsing LLM response as JSON even after repair attempt.');\n        console.error('Raw LLM Response before cleaning:', rawText);\n        console.error('Cleaned JSON string attempt:', cleanedJsonString);\n        console.error('Repaired JSON string attempt (which also failed):', (repairError as Error).message);\n        throw new Error(`Invalid JSON response from LLM: ${(jsonError as Error).message}. Repair attempt failed: ${(repairError as Error).message}`);\n      }\n    }\n\n    let llmOutput: LLMOutput;\n\n    // --- Logic to handle array or object structure (already correct) ---\n    if (Array.isArray(parsedResult)) {\n      // If LLM returned an array, assume it's the 'changes' array\n      console.warn(\"LLM returned an array directly instead of the full LLMOutput object. Wrapping it as 'changes'.\");\n      llmOutput = {\n        changes: parsedResult as ProposedFileChange[], // Cast to the expected array type\n        summary: \"Changes proposed by AI (summary not provided by LLM).\", // Default summary\n        thoughtProcess: \"LLM returned only the changes array, so a default summary and thought process are provided.\"\n      };\n    } else if (typeof parsedResult === 'object' && parsedResult !== null) {\n      // If LLM returned an object, validate its structure\n      if (Array.isArray(parsedResult.changes) && typeof parsedResult.summary === 'string') {\n        llmOutput = parsedResult as LLMOutput; // It matches the expected LLMOutput interface\n      } else {\n        // Object, but missing required properties like 'changes' or 'summary'\n        console.error('Parsed LLM output object is missing expected \"changes\" array or \"summary\" string.');\n        console.error('Received object (stringified):', JSON.stringify(parsedResult, null, 2));\n        throw new Error('LLM response object missing expected \"changes\" array or \"summary\" string.');\n      }\n    } else {\n      // Neither an array nor an object, or null\n      console.error('Parsed LLM output is neither an array nor an object, or null:', typeof parsedResult, parsedResult);\n      throw new Error('Invalid top-level JSON structure from LLM. Expected an object or an array.');\n    }\n    // --- End Logic ---\n\n    // Now, `llmOutput` is guaranteed to be an LLMOutput object, proceed with detailed validation of its contents\n    llmOutput.changes.forEach(change => {\n        if (!change.filePath || !['add', 'modify', 'delete'].includes(change.action)) {\n            throw new Error(`Invalid change object found: ${JSON.stringify(change)}. Missing filePath or invalid action.`);\n        }\n        // Warn if newContent is missing for add/modify, but don't stop execution\n        if ((change.action === 'add' || change.action === 'modify') && change.newContent === undefined) {\n             console.warn(`Warning: Change for ${change.filePath} (action: ${change.action}) has undefined newContent. This might be an issue and could lead to empty files.`);\n        }\n    });\n\n    return llmOutput;\n\n  } catch (error: any) {\n    if (error.response && error.response.error) {\n      console.error(`Gemini API Error: ${error.response.error.message}`);\n      if (error.response.error.details) {\n        console.error('Details:', error.response.error.details);\n      }\n      if (error.response.error.status) {\n        console.error('Status:', error.response.error.status);\n      }\n    } else {\n      console.error(`Error calling LLM: ${(error as Error).message}`);\n    }\n    throw new Error(`Failed to get response from LLM: ${(error as Error).message}`);\n  }\n}\n\n```\n",
  "rawLLMResponse": {
    "summary": "Modified `llmOrchestrator.ts` to utilize the NestJS Google Gemini API endpoint for content generation. This change removes the direct dependency on the `@google/generative-ai` SDK from the orchestration layer and delegates the LLM interaction to the NestJS backend. The `fullPrompt` and the `systemInstruction` (for output format) are now sent as parameters to the NestJS `generate-text` endpoint.",
    "changes": [
      {
        "filePath": "src/llm/llmOrchestrator.ts",
        "action": "modify",
        "newContent": "import { promises as fs } from 'fs';\nimport * as path from 'path';\n// Removed direct GoogleGenerativeAI import as interaction is now via NestJS API\nimport { LLMInput, LLMOutput, ProposedFileChange } from '../types';\nimport { buildLLMPrompt } from './contextPreparer';\nimport { repairJsonBadEscapes } from './jsonRepair';\n\n// Access your API key (ensure dotenv is configured in index.ts) - No longer needed for direct Gemini calls\n// const API_KEY = process.env.GOOGLE_GEMINI_API_KEY;\n// const MODEL = process.env.GOOGLE_GEMINI_MODEL || 'gemini-1.5-pro-latest';\n\nconst NESTJS_API_BASE_URL = process.env.NESTJS_API_BASE_URL;\n\nif (!NESTJS_API_BASE_URL) {\n  console.error('Error: NESTJS_API_BASE_URL environment variable not set.');\n  console.error('Please create a .env file in the project root with NESTJS_API_BASE_URL=\"http://localhost:3000\" (or your NestJS API URL).');\n  process.exit(1);\n}\n\n// No longer instantiate GoogleGenerativeAI directly\n// const genAI = new GoogleGenerativeAI(API_KEY);\n// const model = genAI.getGenerativeModel({ model: MODEL });\n\n// Safety settings are now handled by the NestJS backend\n// const safetySettings = [\n//   {\n//     category: HarmCategory.HARM_CATEGORY_HARASSMENT,\n//     threshold: HarmBlockThreshold.BLOCK_NONE,\n//   },\n//   {\n//     category: HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n//     threshold: HarmBlockThreshold.BLOCK_NONE,\n//   },\n//   {\n//     category: HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n//     threshold: HarmBlockThreshold.BLOCK_NONE,\n//   },\n//   {\n//     category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n//     threshold: HarmBlockThreshold.BLOCK_NONE,\n//   },\n// ];\nconst LOGS_DIR = path.join(process.cwd(), '.ai-editor-logs'); // Logs directory at project root\n\n/**\n * Saves the raw text response from the LLM to a timestamped JSON file.\n * The file is saved in a `.ai-editor-logs` directory at the project root.\n * @param rawText The raw string response from the LLM.\n * @param prompt The original prompt sent to the LLM (for context in the log file).\n */\nasync function saveRawLLMResponse(rawText: string, prompt: string): Promise<void> {\n  try {\n    await fs.mkdir(LOGS_DIR, { recursive: true }); // Ensure log directory exists\n\n    const timestamp = new Date().toISOString().replace(/[:.]/g, '-'); // YYYY-MM-DDTHH-MM-SS-MSZ\n    const fileName = `llm-response-${timestamp}.json`; // Using .json as it's expected to be JSON\n    const filePath = path.join(LOGS_DIR, fileName);\n\n    const logContent = {\n      timestamp: new Date().toISOString(),\n      prompt: prompt,\n      // Attempt to parse if it's JSON, otherwise store as string for better logging\n      rawLLMResponse: (() => {\n        try {\n          return JSON.parse(rawText);\n        } catch {\n          return rawText;\n        }\n      })(),\n    };\n\n    await fs.writeFile(filePath, JSON.stringify(logContent, null, 2), 'utf-8');\n    console.log(`  📝 Saved raw LLM response to: ${path.relative(process.cwd(), filePath)}`);\n  } catch (error) {\n    console.error(`  ❌ Error saving raw LLM response to file: ${(error as Error).message}`);\n  }\n}\n/**\n * Extracts a JSON string from text that might be wrapped in markdown code blocks.\n * This makes parsing more robust against LLM formatting variations.\n * @param text The raw text from the LLM.\n * @returns The extracted JSON string, or the original text if no JSON block is found.\n */\nfunction extractJsonFromMarkdown(text: string): string {\n    const jsonBlockRegex = /```json\\n([\\s\\S]*?)\\n```/;\n    const match = text.match(jsonBlockRegex);\n    if (match && match[1]) {\n        return match[1].trim();\n    }\n    // If it's not wrapped in a JSON block, assume it's pure JSON and just trim it.\n    return text.trim();\n}\n\n/**\n * Calls the Google Gemini LLM API via the NestJS backend and processes the structured JSON response.\n *\n * @param input The structured LLMInput object.\n * @returns A promise that resolves to the LLMOutput.\n */\nexport async function callLLM(input: LLMInput, projectRoot: string): Promise<LLMOutput> {\n  const fullPrompt = buildLLMPrompt(input, projectRoot);\n  // This constructs the system instruction based on the LLMInput, which is passed to NestJS backend\n  const systemInstructionForLLM = `${input.additionalInstructions}\\n\\n${input.expectedOutputFormat}`;\n\n  console.log('\\n--- Prompt sent to LLM ---');\n  // console.log(fullPrompt); // Uncomment for debugging the full prompt\n  console.log(`Prompt size: ${fullPrompt.length} characters.`);\n  console.log('--------------------------\\n');\n\n  try {\n    // Make an HTTP POST request to the NestJS backend's generate-text endpoint\n    // The NestJS endpoint will then call the Gemini API\n    const response = await fetch(`${NESTJS_API_BASE_URL}/api/gemini/file/generate-text`, {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json',\n        // IMPORTANT: If your NestJS API requires authentication (e.g., JWT), you will need to add an 'Authorization' header here.\n        // Example: 'Authorization': `Bearer YOUR_JWT_TOKEN`\n      },\n      body: JSON.stringify({\n        prompt: fullPrompt,\n        systemInstruction: systemInstructionForLLM,\n        // conversationId: 'your-optional-conversation-id' // Add if you implement conversation tracking in llmOrchestrator\n      }),\n    });\n\n    if (!response.ok) {\n      const errorData = await response.json().catch(() => ({ message: response.statusText }));\n      console.error(`NestJS API Error (${response.status}):`, errorData);\n      throw new Error(`Failed to get response from NestJS API: ${errorData.message || 'Unknown error'}`);\n    }\n\n    let rawText = await response.text();\n\n    // Save raw LLM response (from NestJS, which is from Gemini) for debugging and auditing\n    await saveRawLLMResponse(rawText, fullPrompt);\n\n    console.log('\\n--- Raw LLM Response (from NestJS via Gemini) ---');\n    console.log(rawText);\n    console.log('--------------------------------------------------\\n');\n\n    let cleanedJsonString = extractJsonFromMarkdown(rawText);\n\n    let parsedResult: any; // Use 'any' initially as the top-level structure might vary\n    try {\n      parsedResult = JSON.parse(cleanedJsonString);\n    } catch (jsonError) {\n      console.warn('Warning: Initial JSON parsing failed. Attempting to repair bad escaped characters.');\n      try {\n        const repairedJsonString = repairJsonBadEscapes(cleanedJsonString);\n        parsedResult = JSON.parse(repairedJsonString);\n        console.log('JSON parsing succeeded after repair.');\n      } catch (repairError) {\n        console.error('Error parsing LLM response as JSON even after repair attempt.');\n        console.error('Raw LLM Response before cleaning:', rawText);\n        console.error('Cleaned JSON string attempt:', cleanedJsonString);\n        console.error('Repaired JSON string attempt (which also failed):', (repairError as Error).message);\n        throw new Error(`Invalid JSON response from LLM: ${(jsonError as Error).message}. Repair attempt failed: ${(repairError as Error).message}`);\n      }\n    }\n\n    let llmOutput: LLMOutput;\n\n    // --- Logic to handle array or object structure (already correct) ---\n    if (Array.isArray(parsedResult)) {\n      // If LLM returned an array, assume it's the 'changes' array\n      console.warn(\"LLM returned an array directly instead of the full LLMOutput object. Wrapping it as 'changes'.\");\n      llmOutput = {\n        changes: parsedResult as ProposedFileChange[], // Cast to the expected array type\n        summary: \"Changes proposed by AI (summary not provided by LLM).\", // Default summary\n        thoughtProcess: \"LLM returned only the changes array, so a default summary and thought process are provided.\"\n      };\n    } else if (typeof parsedResult === 'object' && parsedResult !== null) {\n      // If LLM returned an object, validate its structure\n      if (Array.isArray(parsedResult.changes) && typeof parsedResult.summary === 'string') {\n        llmOutput = parsedResult as LLMOutput; // It matches the expected LLMOutput interface\n      } else {\n        // Object, but missing required properties like 'changes' or 'summary'\n        console.error('Parsed LLM output object is missing expected \"changes\" array or \"summary\" string.');\n        console.error('Received object (stringified):', JSON.stringify(parsedResult, null, 2));\n        throw new Error('LLM response object missing expected \"changes\" array or \"summary\" string.');\n      }\n    } else {\n      // Neither an array nor an object, or null\n      console.error('Parsed LLM output is neither an array nor an object, or null:', typeof parsedResult, parsedResult);\n      throw new Error('Invalid top-level JSON structure from LLM. Expected an object or an array.');\n    }\n    // --- End Logic ---\n\n    // Now, `llmOutput` is guaranteed to be an LLMOutput object, proceed with detailed validation of its contents\n    llmOutput.changes.forEach(change => {\n        if (!change.filePath || !['add', 'modify', 'delete'].includes(change.action)) {\n            throw new Error(`Invalid change object found: ${JSON.stringify(change)}. Missing filePath or invalid action.`);\n        }\n        // Warn if newContent is missing for add/modify, but don't stop execution\n        if ((change.action === 'add' || change.action === 'modify') && change.newContent === undefined) {\n             console.warn(`Warning: Change for ${change.filePath} (action: ${change.action}) has undefined newContent. This might be an issue and could lead to empty files.`);\n        }\n    });\n\n    return llmOutput;\n\n  } catch (error: any) {\n    // Error handling for HTTP fetch or JSON parsing\n    console.error(`Error calling NestJS API for LLM generation: ${(error as Error).message}`);\n    throw new Error(`Failed to get response from LLM (via NestJS API): ${(error as Error).message}`);\n  }\n}\n",
        "reason": "Updated `llmOrchestrator` to use `fetch` to communicate with the NestJS API's Google Gemini endpoint (`/api/gemini/file/generate-text`). This delegates the direct LLM interaction to the backend, removing the need for the `@google/generative-ai` SDK in this module. The `fullPrompt` and the structured `systemInstruction` are passed as the request body. Added `NESTJS_API_BASE_URL` environment variable check."
      }
    ]
  }
}